{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster the data using k-means\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# normalize the data using sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data as df\n",
    "breast_wisc_data = pd.read_csv('breast_wisc_dataset.csv')\n",
    "cyber_data = pd.read_csv('cybersecurity_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    395\n",
      "1     13\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "breast_X_train, breast_X_test, breast_y_train, breast_y_test = train_test_split(breast_wisc_data.iloc[:, :-1], breast_wisc_data.iloc[:, -1], test_size=0.2, random_state=42)\n",
    "cyber_X_train, cyber_X_test, cyber_y_train, cyber_y_test = train_test_split(cyber_data.iloc[:, :-1], cyber_data.iloc[:, -1], test_size=0.2, random_state=42)\n",
    "# turn y into 0 and 1\n",
    "breast_y_train = breast_y_train.map({'Benign': 0, 'Malignant': 1})\n",
    "breast_y_test = breast_y_test.map({'Benign': 0, 'Malignant': 1})\n",
    "\n",
    "cyber_y_train = cyber_y_train.map({-1: 0, 1: 1})\n",
    "cyber_y_test = cyber_y_test.map({-1: 0, 1: 1})\n",
    "print(cyber_y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kmeans(data, k):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(data)\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd_ss = StandardScaler().fit_transform(breast_X_train)\n",
    "bwd_mm = MinMaxScaler().fit_transform(breast_X_train)\n",
    "bwd_rs = RobustScaler().fit_transform(breast_X_train)\n",
    "bwd_mas = MaxAbsScaler().fit_transform(breast_X_train)\n",
    "\n",
    "kmeans_ss = do_kmeans(bwd_ss, 2)\n",
    "kmeans_mm = do_kmeans(bwd_mm, 2)\n",
    "kmeans_rs = do_kmeans(bwd_rs, 2)\n",
    "kmeans_mas = do_kmeans(bwd_mas, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_masking(y_pred, y_true):\n",
    "    pred_labels = np.zeros_like(y_true)\n",
    "    for i in range(len(np.unique(y_pred))):\n",
    "        mask = (y_pred == i)\n",
    "        pred_labels[mask] = mode(y_true[mask])[0]\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/t_9r39tx0s99sqy0hfqfvzym0000gn/T/ipykernel_63677/3256086368.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  pred_labels[mask] = mode(y_true[mask])[0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_ss = resolve_masking(kmeans_ss.labels_, breast_y_train)\n",
    "y_pred_mm = resolve_masking(kmeans_mm.labels_, breast_y_train)\n",
    "y_pred_rs = resolve_masking(kmeans_rs.labels_, breast_y_train)\n",
    "y_pred_mas = resolve_masking(kmeans_mas.labels_, breast_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the accuracy of the kmeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_ss = accuracy_score(breast_y_train, kmeans_ss.labels_)\n",
    "acc_mm = accuracy_score(breast_y_train, kmeans_mm.labels_)\n",
    "acc_rs = accuracy_score(breast_y_train, kmeans_rs.labels_)\n",
    "acc_mas = accuracy_score(breast_y_train, kmeans_mas.labels_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for StandardScaler: 0.9010989010989011\n",
      "Accuracy for MinMaxScaler: 0.9208791208791208\n",
      "Accuracy for RobustScaler: 0.8505494505494505\n",
      "Accuracy for MaxAbsScaler: 0.9142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for StandardScaler: {acc_ss}\")\n",
    "print(f\"Accuracy for MinMaxScaler: {acc_mm}\")\n",
    "print(f\"Accuracy for RobustScaler: {acc_rs}\")\n",
    "print(f\"Accuracy for MaxAbsScaler: {acc_mas}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans Accuracy\n",
    "We get the best accuracy with the MinMaxScalar and the worst accuracy with the RobustScalar\n",
    "\n",
    "Accuracy for StandardScaler: `0.9010989010989011`\n",
    "\n",
    "Accuracy for MinMaxScaler: `0.9208791208791208`\n",
    "\n",
    "Accuracy for RobustScaler: `0.8505494505494505`\n",
    "\n",
    "Accuracy for MaxAbsScaler: `0.9142857142857143`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber_ss = StandardScaler().fit_transform(cyber_X_train)\n",
    "cyber_mm = MinMaxScaler().fit_transform(cyber_X_train)\n",
    "cyber_rs = RobustScaler().fit_transform(cyber_X_train)\n",
    "cyber_mas = MaxAbsScaler().fit_transform(cyber_X_train)\n",
    "\n",
    "kmeans_cyber_ss = do_kmeans(cyber_ss, 2)\n",
    "kmeans_cyber_mm = do_kmeans(cyber_mm, 2)\n",
    "kmeans_cyber_rs = do_kmeans(cyber_rs, 2)\n",
    "kmeans_cyber_mas = do_kmeans(cyber_mas, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/t_9r39tx0s99sqy0hfqfvzym0000gn/T/ipykernel_63677/3256086368.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  pred_labels[mask] = mode(y_true[mask])[0]\n",
      "/var/folders/wk/t_9r39tx0s99sqy0hfqfvzym0000gn/T/ipykernel_63677/3256086368.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  pred_labels[mask] = mode(y_true[mask])[0]\n",
      "/var/folders/wk/t_9r39tx0s99sqy0hfqfvzym0000gn/T/ipykernel_63677/3256086368.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  pred_labels[mask] = mode(y_true[mask])[0]\n",
      "/var/folders/wk/t_9r39tx0s99sqy0hfqfvzym0000gn/T/ipykernel_63677/3256086368.py:5: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  pred_labels[mask] = mode(y_true[mask])[0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_cyber_ss = resolve_masking(do_kmeans(cyber_ss, 2).labels_, cyber_y_train)\n",
    "y_pred_cyber_mm = resolve_masking(do_kmeans(cyber_mm, 2).labels_, cyber_y_train)\n",
    "y_pred_cyber_rs = resolve_masking(do_kmeans(cyber_rs, 2).labels_, cyber_y_train)\n",
    "y_pred_cyber_mas = resolve_masking(do_kmeans(cyber_mas, 2).labels_, cyber_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LHI(pred_labels, true_labels):\n",
    "    ami = adjusted_mutual_info_score(pred_labels, true_labels)\n",
    "    return 1-ami\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHI for StandardScaler: 1.0\n",
      "LHI for MinMaxScaler: 1.0\n",
      "LHI for RobustScaler: 1.0\n",
      "LHI for MaxAbsScaler: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"LHI for StandardScaler: {get_LHI(y_pred_cyber_ss, cyber_y_train)}\")\n",
    "print(f\"LHI for MinMaxScaler: {get_LHI(y_pred_cyber_mm, cyber_y_train)}\")\n",
    "print(f\"LHI for RobustScaler: {get_LHI(y_pred_cyber_rs, cyber_y_train)}\")\n",
    "print(f\"LHI for MaxAbsScaler: {get_LHI(y_pred_cyber_mas, cyber_y_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to the sparsity of the cyber data, kmeans (as ordered by the problem) has a very hard time clustering the data.\n",
    "\n",
    "LHI for StandardScaler: `1.0`\n",
    "\n",
    "LHI for MinMaxScaler: `1.0`\n",
    "\n",
    "LHI for RobustScaler: `1.0`\n",
    "\n",
    "LHI for MaxAbsScaler: `1.0`\n",
    "\n",
    "Instead let's try DBSCAN for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def do_dbscan(data, eps, min_samples):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(data)\n",
    "    return dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_ss = do_dbscan(cyber_ss, 0.5, 5)\n",
    "dbscan_mm = do_dbscan(cyber_mm, 0.5, 5)\n",
    "dbscan_rs = do_dbscan(cyber_rs, 0.5, 5)\n",
    "dbscan_mas = do_dbscan(cyber_mas, 0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHI for StandardScaler: 1.0014210924665643\n",
      "LHI for MinMaxScaler: 0.9344306863676856\n",
      "LHI for RobustScaler: 1.0066579493467414\n",
      "LHI for MaxAbsScaler: 0.9839699002616406\n"
     ]
    }
   ],
   "source": [
    "print(f\"LHI for StandardScaler: {get_LHI(dbscan_ss.labels_, cyber_y_train)}\")\n",
    "print(f\"LHI for MinMaxScaler: {get_LHI(dbscan_mm.labels_, cyber_y_train)}\")\n",
    "print(f\"LHI for RobustScaler: {get_LHI(dbscan_rs.labels_, cyber_y_train)}\")\n",
    "print(f\"LHI for MaxAbsScaler: {get_LHI(dbscan_mas.labels_, cyber_y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get much better results for AMI (and LHI by extension) by using DBSCAN for clustering because it is far more sensitive to outliers\n",
    "\n",
    "LHI for StandardScaler: `1.0014210924665643`\n",
    "\n",
    "LHI for MinMaxScaler: `0.9344306863676856`\n",
    "\n",
    "LHI for RobustScaler: `1.0066579493467414`\n",
    "\n",
    "LHI for MaxAbsScaler: `0.9839699002616406`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
